{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#costruiamo la bag of words eliminando le stop-words\n",
    "count=CountVectorizer(stop_words='english',\n",
    "                     max_df=.1, #Le parole per essere considerate devono avere una frequenza massima del 10%, altrimenti le scaritiamo\n",
    "                     max_features=5000) #consideriamo le 5000 parole più ricorrenti (LDA è più efficace con set ridotti)\n",
    "X=count.fit_transform(df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#usiamo LDA per classificare i vari topic dei documenti\n",
    "lda=LatentDirichletAllocation(n_topics=10, # vogliamo trovare 10 topic\n",
    "                             random_state=123,\n",
    "                             verbose=1, \n",
    "                             learning_method='batch') #con batch si esegue la stima su tutti i training data in una sola iterazione (esiste anche il metodo online che è più accurato) \n",
    "X_topics=lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10 topic per 5000 parole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fissiamo il numero delle paroel più ricorrenti da visualizzare per ogni topic\n",
    "n_top_words=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "worst minutes script awful stupid\n",
      "Topic 2:\n",
      "family mother father girl children\n",
      "Topic 3:\n",
      "american war dvd music tv\n",
      "Topic 4:\n",
      "human audience cinema art feel\n",
      "Topic 5:\n",
      "police guy car dead murder\n",
      "Topic 6:\n",
      "horror house gore blood sex\n",
      "Topic 7:\n",
      "role performance comedy actor performances\n",
      "Topic 8:\n",
      "series episode episodes tv season\n",
      "Topic 9:\n",
      "book version original effects read\n",
      "Topic 10:\n",
      "action kids fun fight animation\n"
     ]
    }
   ],
   "source": [
    "#visualizziamo le parole\n",
    "feature_names=count.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic %d:\" % (topic_idx+1))\n",
    "    print(\" \".join([feature_names[i] \n",
    "                   for i in topic.argsort()\\\n",
    "                  [:-n_top_words - 1:-1]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Film horror #1:\n",
      "Once upon a time in a castle...... Two little girls are playing in the garden's castle. They are sisters. A blonde little girl (Kitty) and a brunette one (Evelyn). Evelyn steals Kitty's doll. Kitty pursues Evelyn. Running through long corridors, they reach the room where their grandfather, sitting o ...\n",
      "\n",
      "Film horror #2:\n",
      "Emilio Miraglia's first Giallo feature, The Night Evelyn Came Out of the Grave, was a great combination of Giallo and Gothic horror - and this second film is even better! We've got more of the Giallo side of the equation this time around, although Miraglia doesn't lose the Gothic horror stylings tha ...\n",
      "\n",
      "Film horror #3:\n",
      "House of Dracula works from the same basic premise as House of Frankenstein from the year before; namely that Universal's three most famous monsters; Dracula, Frankenstein's Monster and The Wolf Man are appearing in the movie together. Naturally, the film is rather messy therefore, but the fact that ...\n"
     ]
    }
   ],
   "source": [
    "#per essere sicuri possiamo visualizzare alcune recensioni relative a un topic. \n",
    "#Ad esempio per l'horror (topic 6, indice 5)\n",
    "horror=X_topics[:, 5].argsort()[::-1]\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]): #prime 3 recensioni\n",
    "    print('\\nFilm horror #%d:'% (iter_idx+1))\n",
    "    print(df['review'][movie_idx][:300], '...')#prime 300 parole della recensione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
