{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.keras as keras\n",
    "import os\n",
    "import struct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carichiamo il database: ritorna due array n (numero di campioni) x m (numero di feature (pixel)).\n",
    "#60000 training digits, e 10000 test digits. Le immagini sono 28x28 pixel in scala di grigio, che\n",
    "#qui vengono convertite in vettori unidimensionali di riga (784 righe oper immagine). \n",
    "#Il secondo vettore contiene le variabili target (class labels 0-9 delle cifre scritte a mano)\n",
    "def load_mnist(path, kind='train'):\n",
    "    labels_path=os.path.join(path,\n",
    "                            '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path=os.path.join(path,\n",
    "                            '%s-images-idx3-ubyte' % kind)\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "                            magic, n= struct.unpack('>II', \n",
    "                                                    lbpath.read(8))\n",
    "                            labels= np.fromfile(lbpath, \n",
    "                                                dtype=np.uint8)\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "                            magic, num, rwos, cols= struct.unpack('>IIII', \n",
    "                                                                  imgpath.read(16))\n",
    "                            images= np.fromfile(imgpath, \n",
    "                                                dtype=np.uint8).reshape(\n",
    "                                                len(labels), 784)\n",
    "                            images=((images/255.)-.5)*2\n",
    "    return images, labels                       \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, Columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train= load_mnist('', kind='train')\n",
    "print ('Rows: %d, Columns: %d' % (X_train.shape[0], X_train.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10000, Columns: 784\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test= load_mnist('', kind='t10k')\n",
    "print ('Rows: %d, Columns: %d' % (X_test.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Media e deviazione standard per standardizzazione\n",
    "mean_vals=np.mean(X_train, axis=0)\n",
    "std_val=np.std(X_train)\n",
    "X_train_centered=(X_train - mean_vals)/std_val\n",
    "X_test_centered=(X_test - mean_vals)/std_val\n",
    "del X_train, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_centered.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settiamo il random seed\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codifica one-hot encoding\n",
    "y_train_onehot=keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le prime 3 label:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "print('Le prime 3 label: ', y_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le prime 3 label codificate one-hot:  [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Le prime 3 label codificate one-hot: ', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rete neurale\n",
    "model=keras.models.Sequential()\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50, #dimensione di uscita\n",
    "        input_dim=X_train_centered.shape[1], # dimensione di ingresso\n",
    "        kernel_initializer='glorot_uniform', # inizializzazioen dei pesi\n",
    "        bias_initializer='zeros', #inizializzazione dei pesi\n",
    "        activation='tanh'))# funzione di attivazione\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=50, #dimensione di uscita\n",
    "        input_dim=50, # dimensione di ingresso\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='tanh'))\n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "        units=y_train_onehot.shape[1], #dimensione di uscita\n",
    "        input_dim=50, # dimensione di ingresso\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='softmax'))\n",
    "#Ottimizzatore della funzione costo\n",
    "sgd_optimizer = keras.optimizers.SGD(# minimizziamo con stochastic gradient descent\n",
    "    lr=0.001, decay=1e-7, momentum=.9)\n",
    "model.compile(optimizer=sgd_optimizer,\n",
    "             loss='categorical_crossentropy') #funzione costo logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0426 - val_loss: 0.1057\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.0414 - val_loss: 0.1060\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.0405 - val_loss: 0.1064\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 3s 51us/step - loss: 0.0394 - val_loss: 0.1063\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 3s 53us/step - loss: 0.0384 - val_loss: 0.1057\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0374 - val_loss: 0.1059\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0364 - val_loss: 0.1065\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.0356 - val_loss: 0.1073\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0347 - val_loss: 0.1074\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.0339 - val_loss: 0.1077\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0330 - val_loss: 0.1078\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0322 - val_loss: 0.1075\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 3s 58us/step - loss: 0.0314 - val_loss: 0.1083\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0306 - val_loss: 0.1084\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.0299 - val_loss: 0.1091\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 3s 61us/step - loss: 0.0292 - val_loss: 0.1093\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 3s 63us/step - loss: 0.0285 - val_loss: 0.1093\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0278 - val_loss: 0.1090\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.0272 - val_loss: 0.1095\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0266 - val_loss: 0.1099\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0259 - val_loss: 0.1098\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.0253 - val_loss: 0.1106\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.0247 - val_loss: 0.1111\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0242 - val_loss: 0.1114\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0236 - val_loss: 0.1119\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0231 - val_loss: 0.1113\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0225 - val_loss: 0.1119\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 3s 58us/step - loss: 0.0220 - val_loss: 0.1121\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0215 - val_loss: 0.1131\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 3s 55us/step - loss: 0.0211 - val_loss: 0.1129\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0206 - val_loss: 0.1134\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0202 - val_loss: 0.1134\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0197 - val_loss: 0.1137\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0193 - val_loss: 0.1141\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0189 - val_loss: 0.1136\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0184 - val_loss: 0.1143\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 3s 54us/step - loss: 0.0181 - val_loss: 0.1146\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0177 - val_loss: 0.1149\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0173 - val_loss: 0.1158\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 3s 58us/step - loss: 0.0170 - val_loss: 0.1151\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0166 - val_loss: 0.1164\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0163 - val_loss: 0.1163\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0159 - val_loss: 0.1160\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 3s 56us/step - loss: 0.0156 - val_loss: 0.1164\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 3s 58us/step - loss: 0.0153 - val_loss: 0.1170\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 3s 60us/step - loss: 0.0150 - val_loss: 0.1166\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0147 - val_loss: 0.1175\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 3s 57us/step - loss: 0.0144 - val_loss: 0.1178\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 3s 58us/step - loss: 0.0141 - val_loss: 0.1179\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 3s 59us/step - loss: 0.0139 - val_loss: 0.1183\n"
     ]
    }
   ],
   "source": [
    "#Fit\n",
    "history= model.fit(X_train_centered, y_train_onehot,\n",
    "                  batch_size=64, epochs=50, #apprendimento su minibatch di 64 campioni con 50 iterazioni\n",
    "                  verbose=1,\n",
    "                  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "y_train_pred=model.predict_classes(X_train_centered, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime 3 predizioni:  [5 0 4]\n",
      "Accuratezza training: 99.61%\n"
     ]
    }
   ],
   "source": [
    "correct_preds=np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc=correct_preds/y_train.shape[0]\n",
    "print('Prime 3 predizioni: ', y_train_pred[:3])\n",
    "print('Accuratezza training: %.2f%%' % (train_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prime 3 predizioni:  [5 0 4]\n",
      "Accuratezza test: 96.27%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred=model.predict_classes(X_test_centered, verbose=0)\n",
    "correct_preds=np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc=correct_preds/y_test.shape[0]\n",
    "print('Prime 3 predizioni: ', y_train_pred[:3])\n",
    "print('Accuratezza test: %.2f%%' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
